{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "34894d88",
   "metadata": {},
   "source": [
    "# End-to-End ML (Part 3): Model Selection and Deployment\n",
    "\n",
    "\n",
    "Goal:\n",
    "- Use k-fold cross validation on the one-hot data\n",
    "- Show model ensembling of the LR and RF models\n",
    "- Do some ML Ops / model analysis on the final ensembled model\n",
    "- Show how to deploy this model to \"production\" using streamlit (maybe HF spaces?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "43dad208",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score, f1_score, confusion_matrix, accuracy_score, precision_score, recall_score\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "seed = 123\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c66d587b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "58239886",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_scores(y,yhat):\n",
    "    print('accuracy: ', round(accuracy_score(y, yhat), 4))\n",
    "    print('precision: ', round(precision_score(y, yhat), 4))\n",
    "    print('recall: ', round(recall_score(y, yhat), 4))\n",
    "    print('f1: ', round(f1_score(y, yhat), 4))\n",
    "    print('auc: ', round(roc_auc_score(y, yhat), 4))\n",
    "    print('confusion matrix:\\n', confusion_matrix(y, yhat))\n",
    "    \n",
    "def clean_data(df):\n",
    "    df['Sex'] = df['Sex'].replace(to_replace='male', value=0)\n",
    "    df['Sex'] = df['Sex'].replace(to_replace='female', value=1)\n",
    "\n",
    "    df['Age_missing'] = df['Age'].isna().astype(int)\n",
    "    mean_age = df['Age'].dropna().mean()\n",
    "    df['Age'] = df['Age'].fillna(value=mean_age)\n",
    "    max_age = df['Age'].max()\n",
    "    df['Age'] /= max_age\n",
    "    \n",
    "    df['Fare'] = df['Fare'].fillna(value=df['Fare'].mean())\n",
    "    df['Fare'] = np.log(df['Fare'] + 1)\n",
    "    max_fare, min_fare = df['Fare'].max(), df['Fare'].min()\n",
    "    df['Fare'] =  (df['Fare'] - min_fare) / (max_fare - min_fare)\n",
    "\n",
    "    mode_embarked = df['Embarked'].dropna().mode().item()\n",
    "    df['Embarked'] = df['Embarked'].fillna(value=mode_embarked)\n",
    "    df['Embarked'] = df['Embarked'].replace(to_replace='S', value=0)\n",
    "    df['Embarked'] = df['Embarked'].replace(to_replace='C', value=1)\n",
    "    df['Embarked'] = df['Embarked'].replace(to_replace='Q', value=2)\n",
    "    \n",
    "    df['Family'] = df['SibSp'] + df['Parch']\n",
    "    df['Alone'] = (df['Family'] == 0).astype(int)\n",
    "\n",
    "    titles = ['Mr', 'Miss', 'Mrs', 'Master', 'Rare']\n",
    "    titles_dict = {title:idx for (idx,title) in enumerate(titles)}\n",
    "    df['Titles'] = df['Name'].str.extract(' ([A-Za-z]+)\\.')\n",
    "    df['Titles'] = df['Titles'].apply(lambda x: x if x in titles else 'Rare')\n",
    "    df['Titles'] = df['Titles'].apply(lambda x: titles_dict[x])\n",
    "\n",
    "    prefixes = ['PC', 'CA', 'A5', 'SOTONOQ', 'STONO', 'Other']\n",
    "    prefix_dict = {prefix:idx for (idx,prefix) in enumerate(prefixes)}\n",
    "    ticket_prefixes = df['Ticket'].str.split().apply(lambda x: x[0] if len(x) >= 2 else None)\n",
    "    ticket_prefixes = ticket_prefixes.str.replace('/', '')\n",
    "    ticket_prefixes = ticket_prefixes.str.replace('.', '')\n",
    "    df['Prefix'] = ticket_prefixes.apply(lambda x: x if x in prefixes else 'Other')\n",
    "    df['Prefix'] = df['Prefix'].apply(lambda x: prefix_dict[x])\n",
    "    \n",
    "    df['Ticket_freq'] = df.groupby('Ticket')['Ticket'].transform('count')\n",
    "    max_freq = df['Ticket_freq'].max()\n",
    "    df['Ticket_freq'] /= max_freq\n",
    "\n",
    "    levels = {'A': 'ABC', 'B': 'ABC', 'C': 'ABC', 'D': 'DE', 'E': 'DE', 'F': 'FG', 'G': 'FG'}\n",
    "    levels_dict = {level:idx for (idx,level) in enumerate(levels.values())}\n",
    "    df['Level'] = df['Cabin'].fillna(value='?').str.split().apply(lambda x: x[0][0])\n",
    "    df['Level'] = df['Level'].replace('?', np.nan)\n",
    "    df['Level_missing'] = df['Level'].isna().astype(int)\n",
    "    df['Level'] = df['Cabin'].str[0].map(levels)\n",
    "    df['Level'] = df['Level'].apply(lambda x: x if x in levels.values() or pd.isna(x) else 'Other')\n",
    "    mode_level = df['Level'].mode().item()\n",
    "    df['Level'] = df['Level'].replace(np.nan, mode_level)\n",
    "    df['Level'] = df['Level'].apply(lambda x: levels_dict[x])\n",
    "    \n",
    "    df = pd.get_dummies(df, columns=['Pclass', 'Embarked', 'Titles', 'Prefix', 'Level'])\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "83a13edc",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_columns = [\n",
    "    'Sex', 'Age', 'SibSp', 'Parch', 'Fare', 'Age_missing', 'Family', 'Alone', 'Ticket_freq', 'Level_missing', \n",
    "    'Pclass_1', 'Pclass_2', 'Pclass_3', 'Embarked_0', 'Embarked_1', 'Embarked_2', 'Titles_0', 'Titles_1', \n",
    "    'Titles_2', 'Titles_3', 'Titles_4', 'Prefix_0', 'Prefix_1', 'Prefix_2', 'Prefix_3', 'Prefix_4', 'Prefix_5', \n",
    "    'Level_2', 'Level_4', 'Level_6'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bf5dfdab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>PassengerId</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Survived</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Name</th>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sex</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Age</th>\n",
       "      <td>0.275</td>\n",
       "      <td>0.475</td>\n",
       "      <td>0.325</td>\n",
       "      <td>0.4375</td>\n",
       "      <td>0.4375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SibSp</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Parch</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ticket</th>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>113803</td>\n",
       "      <td>373450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fare</th>\n",
       "      <td>0.338125</td>\n",
       "      <td>0.685892</td>\n",
       "      <td>0.350727</td>\n",
       "      <td>0.639463</td>\n",
       "      <td>0.352955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cabin</th>\n",
       "      <td>NaN</td>\n",
       "      <td>C85</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C123</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Age_missing</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Family</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Alone</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ticket_freq</th>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.142857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Level_missing</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pclass_1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pclass_2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pclass_3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Embarked_0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Embarked_1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Embarked_2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Titles_0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Titles_1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Titles_2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Titles_3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Titles_4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Prefix_0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Prefix_1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Prefix_2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Prefix_3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Prefix_4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Prefix_5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Level_2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Level_4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Level_6</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     0  \\\n",
       "PassengerId                          1   \n",
       "Survived                             0   \n",
       "Name           Braund, Mr. Owen Harris   \n",
       "Sex                                  0   \n",
       "Age                              0.275   \n",
       "SibSp                                1   \n",
       "Parch                                0   \n",
       "Ticket                       A/5 21171   \n",
       "Fare                          0.338125   \n",
       "Cabin                              NaN   \n",
       "Age_missing                          0   \n",
       "Family                               1   \n",
       "Alone                                0   \n",
       "Ticket_freq                   0.142857   \n",
       "Level_missing                        1   \n",
       "Pclass_1                             0   \n",
       "Pclass_2                             0   \n",
       "Pclass_3                             1   \n",
       "Embarked_0                           1   \n",
       "Embarked_1                           0   \n",
       "Embarked_2                           0   \n",
       "Titles_0                             1   \n",
       "Titles_1                             0   \n",
       "Titles_2                             0   \n",
       "Titles_3                             0   \n",
       "Titles_4                             0   \n",
       "Prefix_0                             0   \n",
       "Prefix_1                             0   \n",
       "Prefix_2                             1   \n",
       "Prefix_3                             0   \n",
       "Prefix_4                             0   \n",
       "Prefix_5                             0   \n",
       "Level_2                              1   \n",
       "Level_4                              0   \n",
       "Level_6                              0   \n",
       "\n",
       "                                                               1  \\\n",
       "PassengerId                                                    2   \n",
       "Survived                                                       1   \n",
       "Name           Cumings, Mrs. John Bradley (Florence Briggs Th...   \n",
       "Sex                                                            1   \n",
       "Age                                                        0.475   \n",
       "SibSp                                                          1   \n",
       "Parch                                                          0   \n",
       "Ticket                                                  PC 17599   \n",
       "Fare                                                    0.685892   \n",
       "Cabin                                                        C85   \n",
       "Age_missing                                                    0   \n",
       "Family                                                         1   \n",
       "Alone                                                          0   \n",
       "Ticket_freq                                             0.142857   \n",
       "Level_missing                                                  0   \n",
       "Pclass_1                                                       1   \n",
       "Pclass_2                                                       0   \n",
       "Pclass_3                                                       0   \n",
       "Embarked_0                                                     0   \n",
       "Embarked_1                                                     1   \n",
       "Embarked_2                                                     0   \n",
       "Titles_0                                                       0   \n",
       "Titles_1                                                       0   \n",
       "Titles_2                                                       1   \n",
       "Titles_3                                                       0   \n",
       "Titles_4                                                       0   \n",
       "Prefix_0                                                       1   \n",
       "Prefix_1                                                       0   \n",
       "Prefix_2                                                       0   \n",
       "Prefix_3                                                       0   \n",
       "Prefix_4                                                       0   \n",
       "Prefix_5                                                       0   \n",
       "Level_2                                                        1   \n",
       "Level_4                                                        0   \n",
       "Level_6                                                        0   \n",
       "\n",
       "                                    2  \\\n",
       "PassengerId                         3   \n",
       "Survived                            1   \n",
       "Name           Heikkinen, Miss. Laina   \n",
       "Sex                                 1   \n",
       "Age                             0.325   \n",
       "SibSp                               0   \n",
       "Parch                               0   \n",
       "Ticket               STON/O2. 3101282   \n",
       "Fare                         0.350727   \n",
       "Cabin                             NaN   \n",
       "Age_missing                         0   \n",
       "Family                              0   \n",
       "Alone                               1   \n",
       "Ticket_freq                  0.142857   \n",
       "Level_missing                       1   \n",
       "Pclass_1                            0   \n",
       "Pclass_2                            0   \n",
       "Pclass_3                            1   \n",
       "Embarked_0                          1   \n",
       "Embarked_1                          0   \n",
       "Embarked_2                          0   \n",
       "Titles_0                            0   \n",
       "Titles_1                            1   \n",
       "Titles_2                            0   \n",
       "Titles_3                            0   \n",
       "Titles_4                            0   \n",
       "Prefix_0                            0   \n",
       "Prefix_1                            0   \n",
       "Prefix_2                            0   \n",
       "Prefix_3                            0   \n",
       "Prefix_4                            0   \n",
       "Prefix_5                            1   \n",
       "Level_2                             1   \n",
       "Level_4                             0   \n",
       "Level_6                             0   \n",
       "\n",
       "                                                          3  \\\n",
       "PassengerId                                               4   \n",
       "Survived                                                  1   \n",
       "Name           Futrelle, Mrs. Jacques Heath (Lily May Peel)   \n",
       "Sex                                                       1   \n",
       "Age                                                  0.4375   \n",
       "SibSp                                                     1   \n",
       "Parch                                                     0   \n",
       "Ticket                                               113803   \n",
       "Fare                                               0.639463   \n",
       "Cabin                                                  C123   \n",
       "Age_missing                                               0   \n",
       "Family                                                    1   \n",
       "Alone                                                     0   \n",
       "Ticket_freq                                        0.285714   \n",
       "Level_missing                                             0   \n",
       "Pclass_1                                                  1   \n",
       "Pclass_2                                                  0   \n",
       "Pclass_3                                                  0   \n",
       "Embarked_0                                                1   \n",
       "Embarked_1                                                0   \n",
       "Embarked_2                                                0   \n",
       "Titles_0                                                  0   \n",
       "Titles_1                                                  0   \n",
       "Titles_2                                                  1   \n",
       "Titles_3                                                  0   \n",
       "Titles_4                                                  0   \n",
       "Prefix_0                                                  0   \n",
       "Prefix_1                                                  0   \n",
       "Prefix_2                                                  0   \n",
       "Prefix_3                                                  0   \n",
       "Prefix_4                                                  0   \n",
       "Prefix_5                                                  1   \n",
       "Level_2                                                   1   \n",
       "Level_4                                                   0   \n",
       "Level_6                                                   0   \n",
       "\n",
       "                                      4  \n",
       "PassengerId                           5  \n",
       "Survived                              0  \n",
       "Name           Allen, Mr. William Henry  \n",
       "Sex                                   0  \n",
       "Age                              0.4375  \n",
       "SibSp                                 0  \n",
       "Parch                                 0  \n",
       "Ticket                           373450  \n",
       "Fare                           0.352955  \n",
       "Cabin                               NaN  \n",
       "Age_missing                           0  \n",
       "Family                                0  \n",
       "Alone                                 1  \n",
       "Ticket_freq                    0.142857  \n",
       "Level_missing                         1  \n",
       "Pclass_1                              0  \n",
       "Pclass_2                              0  \n",
       "Pclass_3                              1  \n",
       "Embarked_0                            1  \n",
       "Embarked_1                            0  \n",
       "Embarked_2                            0  \n",
       "Titles_0                              1  \n",
       "Titles_1                              0  \n",
       "Titles_2                              0  \n",
       "Titles_3                              0  \n",
       "Titles_4                              0  \n",
       "Prefix_0                              0  \n",
       "Prefix_1                              0  \n",
       "Prefix_2                              0  \n",
       "Prefix_3                              0  \n",
       "Prefix_4                              0  \n",
       "Prefix_5                              1  \n",
       "Level_2                               1  \n",
       "Level_4                               0  \n",
       "Level_6                               0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = 'https://raw.githubusercontent.com/datasciencedojo/datasets/master/titanic.csv'\n",
    "df = pd.read_csv(url)\n",
    "df = clean_data(df)\n",
    "df.head().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f5cb5e0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((891, 30), (891,))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = df[feature_columns].values\n",
    "y = df['Survived'].values\n",
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53aae4bc",
   "metadata": {},
   "source": [
    "## Part 3 Notes\n",
    "\n",
    "- Issues changing the seed strongly affecting results (lack of data). Could solve with cross validation?\n",
    "- Danger of overfitting to this particular test set. Really want a model that generalizes to unseen data well. Should really give each score a 2% or so error band; once you do that a lot of these models are basically equivalent.\n",
    "- Which metric to use? Often dangerous to focus on only one and optimize it, as weird edge cases can happen if you ignore others.\n",
    "- We're doing about as well as we can expect with this data. Even Kaggle [discussions](https://www.kaggle.com/code/carlmcbrideellis/titanic-leaderboard-a-score-0-8-is-great) consider 77-85% good scores here. Not worth more effort?\n",
    "- Think about the use case. What are you using this model for? How good does it have to be? What value does it provide? Don't just mindlessly fall into optimizing it. Real life isn't a Kaggle competition.\n",
    "- Selecting the best model isn't about optimizing a metric, but finding best overall fit. Which one is \"good enough\", in the sense that it's accurate enough, fast enough, easy to implement and maintain, (where necessary) easy to interpret, etc.\n",
    "- Possible improvements: Tune the hyperparameters of the above models more. Use cross validation for stable metric estimates. Use other models. Use more advanced resampling techniques like SMOTE/ADASYN. Take the unlabeled \"test\" set from Kaggle, label it with your best model, and use that as new training data on top of what you've already got. Try more advanced categorical encodings like learned embeddings. Better yet, turn all your features into categorical features by thresholding them.\n",
    "-**You need to use k-fold CV. Way too much fluctuation in scores with different seeds. Over 5%.**\n",
    "-**Thinking: Make this one about data cleaning. Do one after this about cross val, pipelines, and deployment.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "34be908c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Onehot\n",
      "\n",
      "Logistic Regression\n",
      "\n",
      "0.8356741573033708 0.8100558659217877\n",
      "0.8429172510518934 0.8202247191011236\n",
      "0.8429172510518934 0.8202247191011236\n",
      "0.8485273492286115 0.7921348314606742\n",
      "0.820476858345021 0.8426966292134831\n",
      "\n",
      "avg acc: 0.8170673529596385\n",
      "\n",
      "Random Forest\n",
      "\n",
      "0.8707865168539326 0.8435754189944135\n",
      "0.8779803646563815 0.8258426966292135\n",
      "0.8583450210378681 0.8370786516853933\n",
      "0.8681626928471248 0.797752808988764\n",
      "0.8457223001402524 0.8651685393258427\n",
      "\n",
      "avg acc: 0.8338836231247253\n"
     ]
    }
   ],
   "source": [
    "kf = KFold(n_splits=5)\n",
    "kf.get_n_splits(X)\n",
    "\n",
    "print('Onehot\\n')\n",
    "\n",
    "print('Logistic Regression\\n')\n",
    "accs = []\n",
    "for i_train, i_test in kf.split(X):\n",
    "    model = LogisticRegressionCV(random_state=seed)\n",
    "    model.fit(X[i_train], y[i_train])\n",
    "    acc_train = model.score(X[i_train], y[i_train])\n",
    "    acc_test = model.score(X[i_test], y[i_test])\n",
    "    accs.append(acc_test)\n",
    "    print(acc_train, acc_test)\n",
    "\n",
    "print()\n",
    "print(f'avg acc: {sum(accs) / len(accs)}')\n",
    "print()\n",
    "\n",
    "print('Random Forest\\n')\n",
    "accs = []\n",
    "for i_train, i_test in kf.split(X):\n",
    "    model = RandomForestClassifier(n_estimators=100, random_state=seed, max_depth=6, min_samples_leaf=2)\n",
    "    model.fit(X[i_train], y[i_train])\n",
    "    acc_train = model.score(X[i_train], y[i_train])\n",
    "    acc_test = model.score(X[i_test], y[i_test])\n",
    "    accs.append(acc_test)\n",
    "    print(acc_train, acc_test)\n",
    "\n",
    "print()\n",
    "print(f'avg acc: {sum(accs) / len(accs)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a59a0e47",
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble = VotingClassifier(estimators=[\n",
    "    ('lr', LogisticRegressionCV(random_state=seed)),\n",
    "    ('rf', RandomForestClassifier(n_estimators=100, random_state=seed, max_depth=6, min_samples_leaf=2)),\n",
    "], voting='hard')\n",
    "\n",
    "# ensemble.fit(X_train, y_train)\n",
    "# ensemble.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13611684",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_test = pd.read_csv(...)\n",
    "# df_test = clean_data(df_test)\n",
    "# X_test = df_test[feature_columns].values\n",
    "# yhat = ensemble.predict(X_test)\n",
    "# df_sub = pd.DataFrame(data=zip(df_raw['PassengerId'].values, yhat), columns=['PassengerId', 'Survived'])\n",
    "# df_sub.to_csv(Path().home()/'Desktop'/'submission.csv', index=False)\n",
    "# ! head -10 ~/Desktop/submission.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27116bc7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c66e374",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "53d2182c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7867564534231201"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = df['Sex'].values.reshape(-1, 1)\n",
    "ensemble.fit(x, y)\n",
    "ensemble.score(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29621280",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29ffbe34",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
