{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "16d84ebe",
   "metadata": {},
   "source": [
    "# Neural Networks (Part 2): Going Deeper\n",
    "\n",
    "In part 2 of this neural networks series of tutorials we'll go into some more advanced ideas that make it easier to train deeper neural networks. We'll discuss concepts like activation functions, schedulers, regularization, normalization, batches and dataloaders, and stochastic optimizers. We won't discuss new architectures yet, and just continue to stick with MLPs for now. Recall that an MLP is any neural network whose blocks are composed of linear layers + activation functions.\n",
    "\n",
    "We'll again load the usual libraries we'll need, set a seed, and set a device for those who'd prefer to work on the GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d5e6b8d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x115db2730>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from sklearn.datasets import make_blobs\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "seed = 12\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8a8ae62e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1a08c66e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cpu'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7502212e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_data(X, y, X_test=None, y_test=None, model=None):\n",
    "    x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n",
    "    y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
    "    xx, yy = np.meshgrid(np.arange(x_min, x_max, 0.01), np.arange(y_min, y_max, 0.01))\n",
    "    grid = np.c_[xx.ravel(), yy.ravel()]\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(8, 8))\n",
    "\n",
    "\n",
    "    classes = np.unique(y)\n",
    "    colors = plt.cm.rainbow(np.linspace(0, 1, len(classes)))\n",
    "    if model is not None:\n",
    "        grid = torch.from_numpy(grid).float()\n",
    "        yhat = model(grid).argmax(dim=1).detach().numpy().reshape(xx.shape)\n",
    "        ax.contourf(xx, yy, yhat, alpha=0.2, cmap=plt.cm.rainbow)\n",
    "        plt.axis(\"tight\")\n",
    "\n",
    "    for j, color in zip(classes, colors):\n",
    "        idx = np.where(y == j)\n",
    "        alpha = 1 if X_test is None else 0.2\n",
    "        plt.scatter(X[idx, 0], X[idx, 1], color=color, label=f'y={j}', edgecolor='black', s=15, alpha=alpha)\n",
    "        if X_test is not None and y_test is not None:\n",
    "            idx = np.where(y_test == j)\n",
    "            plt.scatter(X_test[idx, 0], X_test[idx, 1], color=color, edgecolor='black', s=25, alpha=1)\n",
    "    plt.title('Decision Surface')\n",
    "    plt.axis('tight')\n",
    "\n",
    "    ax.set(aspect='equal', xlabel='$x_1$', ylabel='$x_2$')\n",
    "    ax.legend(loc='upper right')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "717cc659",
   "metadata": {},
   "source": [
    "## Activation Functions\n",
    "\n",
    "Recall that an activation function is any function that follows a linear layer. We've used sigmoid functions thus far for hidden layer activation functions. For output activation functions we've used linear, sigmoid, and softmax funtions.\n",
    "\n",
    "It turns out that the sigmoid function \n",
    "$$\\sigma(z) \\equiv \\frac{1}{1 + e^{-z}}$$ \n",
    "is a bad activation function to use for hidden layers. The reason for this is **gradient vanishing**. Because of the sigmoid's elongated S-shape, if $z$ isn't \"small\" in absolute value, e.g. $|z|=5$, then $\\sigma(z)$ will be close to $\\pm 1$. In these regions the sigmoid will be pretty flat, meaning its derivative (i.e. its gradient) will be approximately zero. When the gradient is approximately zero, gradient descent stops working, and those parameters don't update anymore. This causes the activations to die off, making them practically useless in the network. They can't contribute anymore to learning. Such dying activations have been shown to be common when one tries to use sigmoids hidden activations for deeper networks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1e1f6902",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "z = torch.linspace(-10, 10, 100)\n",
    "sigmoid = F.sigmoid(z)\n",
    "plt.plot(z.numpy(), sigmoid.numpy())\n",
    "plt.xlabel('z')\n",
    "plt.title('Sigmoid')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70471758",
   "metadata": {},
   "source": [
    "Because of this problem, many other activation functions have been proposed over the years and shown to work much better than the sigmoid for hidden layer activations. The most widely used is what's called the **rectified linear unit**, usually just called **ReLU**, defined by\n",
    "$$\n",
    "\\text{ReLU}(z) \\equiv \\max(0, z) = \n",
    "\\begin{cases}\n",
    "0, & z < 0 \\\\\n",
    "z, & z \\geq 0.\n",
    "\\end{cases}\n",
    "$$\n",
    "This function is just a truncated line, with all the negative values set to zero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "36140696",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "z = torch.linspace(-10, 10, 100)\n",
    "relu = F.relu(z)\n",
    "plt.plot(z.numpy(), relu.numpy())\n",
    "plt.xlabel('z')\n",
    "plt.title('ReLU')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "664222c8",
   "metadata": {},
   "source": [
    "The ReLU has turned out to work well across many experiments over the past decade for training neural networks, with gradient vanishing issues happening far less than sigmoids. Because of this, it's still by far the most widely used activation function today, even though minor variations of it have since come along and gained some degree of traction. Examples of these are the leaky ReLU, GELU, SELU, Swish, Mish, etc. We'll stick with ReLUs for most of our tutorials since it tends to work pretty well most of the time.\n",
    "\n",
    "Using a ReLU in pytorch can be done either by using the layer `nn.ReLU` or the function `F.relu`. The other, newer variants just mentioned are accessible as well if you wish to use them.\n",
    "\n",
    "**Note:** The ReLU is just used for *hidden layers*, not the output layer. For the output layer, you still want to use either the linear, sigmoid, or softmax activation depending on what your task is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f203f7be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Linear(in_features=2, out_features=100, bias=True)\n",
       "  (1): ReLU()\n",
       "  (2): Linear(in_features=100, out_features=1, bias=True)\n",
       "  (3): Sigmoid()\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = nn.Sequential(\n",
    "    nn.Linear(2, 100),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(100, 1),\n",
    "    nn.Sigmoid()\n",
    ")\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9e2a4cb",
   "metadata": {},
   "source": [
    "## Regularization\n",
    "\n",
    "Recall from past tutorials that in practice it's usually bad to have zero loss or 100% accuracy on the training dataset, because it probably means you're just memorizing your data instead of discovering the underlying patterns in the data. This phenomenon is called **overfitting**. To help detect and prevent overfitting it's customary to keep a hold-out sample of the dataset that the model doesn't get trained on, and use that dataset to evaluate the performance of the model. Such hold-out datasets are called the **test set** or the **validation set**. A model trained on a training set that also performs well on the test set is said to **generalize**, just a fancy way of saying the model isn't just memorizing the data but actually learning its underlying patterns really well.\n",
    "\n",
    "To see what overfitting looks like let's create a small linear dataset, split it into train and test sets, and try to fit the training set with a large MLP of 8 layers with hidden sizes of 500 neurons. We'll train it for 10,000 iterations on the training data (i.e. the grayed out data in the plot), and evaluate it on the test data (i.e. the black points in the plot). Note that the *true* fit should be a line in this case, as that's how we generated this dataset, a line plus some Gaussian noise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "401ec459",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([30, 1]), torch.Size([30, 1]))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_samples = 30\n",
    "X = torch.linspace(0, 5, num_samples).reshape(-1, 1).to(device)\n",
    "y = X + torch.randn(num_samples).reshape(-1, 1).to(device)\n",
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d963d0ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([24, 1]),\n",
       " torch.Size([24, 1]),\n",
       " torch.Size([6, 1]),\n",
       " torch.Size([6, 1]))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "X_train.shape, y_train.shape, X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4516281b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(X_train, y_train, label='train', color='gray', alpha=0.5, s=5)\n",
    "plt.scatter(X_test, y_test, label='test', color='black', alpha=1, s=15)\n",
    "plt.xlabel('$x$')\n",
    "plt.ylabel('$y$')\n",
    "plt.legend(loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f3fbc92a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Linear(in_features=1, out_features=500, bias=True)\n",
       "  (1): ReLU()\n",
       "  (2): Linear(in_features=500, out_features=500, bias=True)\n",
       "  (3): ReLU()\n",
       "  (4): Linear(in_features=500, out_features=500, bias=True)\n",
       "  (5): ReLU()\n",
       "  (6): Linear(in_features=500, out_features=500, bias=True)\n",
       "  (7): ReLU()\n",
       "  (8): Linear(in_features=500, out_features=500, bias=True)\n",
       "  (9): ReLU()\n",
       "  (10): Linear(in_features=500, out_features=500, bias=True)\n",
       "  (11): ReLU()\n",
       "  (12): Linear(in_features=500, out_features=500, bias=True)\n",
       "  (13): ReLU()\n",
       "  (14): Linear(in_features=500, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = torch.tensor(X).float().to(device)\n",
    "y = torch.tensor(y).float().to(device)\n",
    "X_train = torch.tensor(X_train).float().to(device)\n",
    "y_train = torch.tensor(y_train).float().to(device)\n",
    "X_test = torch.tensor(X_test).float().to(device)\n",
    "y_test = torch.tensor(y_test).float().to(device)\n",
    "\n",
    "num_features = X_train.shape[1]\n",
    "num_hidden = 500\n",
    "num_targets = 1\n",
    "\n",
    "model = nn.Sequential(\n",
    "    nn.Linear(num_features, num_hidden),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(num_hidden, num_hidden),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(num_hidden, num_hidden),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(num_hidden, num_hidden),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(num_hidden, num_hidden),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(num_hidden, num_hidden),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(num_hidden, num_hidden),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(num_hidden, num_targets)\n",
    ")\n",
    "model = model.to(device)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d6d2e261",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba4748dd59404262934aa2a8c97c3e99",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter = 0 \t\t train loss = 0.30887994170188904 \t\t test loss = 1.0303691625595093\n",
      "iter = 1000 \t\t train loss = 0.030806303024291992 \t\t test loss = 0.02472120337188244\n",
      "iter = 2000 \t\t train loss = 0.029723338782787323 \t\t test loss = 0.029680581763386726\n",
      "iter = 3000 \t\t train loss = 0.02871190570294857 \t\t test loss = 0.032898325473070145\n",
      "iter = 4000 \t\t train loss = 0.027320751920342445 \t\t test loss = 0.03407188132405281\n",
      "iter = 5000 \t\t train loss = 0.02563592977821827 \t\t test loss = 0.031092137098312378\n",
      "iter = 6000 \t\t train loss = 0.02366632968187332 \t\t test loss = 0.03314466401934624\n",
      "iter = 7000 \t\t train loss = 0.017538730055093765 \t\t test loss = 0.036950331181287766\n",
      "iter = 8000 \t\t train loss = 0.011787530966103077 \t\t test loss = 0.031028496101498604\n",
      "iter = 9000 \t\t train loss = 0.013204634189605713 \t\t test loss = 0.052232775837183\n",
      "iter = 9999 \t\t train loss = 0.008932610973715782 \t\t test loss = 0.08386954665184021\n"
     ]
    }
   ],
   "source": [
    "num_iters = 10_000\n",
    "loss_fn = nn.MSELoss()\n",
    "opt = torch.optim.SGD(model.parameters(), lr=0.01)\n",
    "for i in tqdm(range(num_iters)):\n",
    "    # training\n",
    "    opt.zero_grad()\n",
    "    yhat = model(X_train)\n",
    "    loss = loss_fn(yhat, y_train)\n",
    "    loss.backward()\n",
    "    opt.step()\n",
    "    # inference\n",
    "    yhat = model(X_test)\n",
    "    test_loss = loss_fn(yhat, y_test)\n",
    "    if i % (num_iters // 10) == 0:\n",
    "        print(f'iter = {i} \\t\\t train loss = {loss / len(X_train)} \\t\\t test loss = {test_loss / len(X_test)}')\n",
    "print(f'iter = {i} \\t\\t train loss = {loss / len(X_train)} \\t\\t test loss = {test_loss / len(X_test)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99899f32",
   "metadata": {},
   "source": [
    "Notice how the training loss is extremely low, almost zero, while the test loss is over an order of magnitude higher higher, and in fact getting *worse* with training. This is the hallmark of overfitting. We can visualize what's happening as well. Here's what our prediction looks like, overlaid on the above plot. Notice how jagged the curve is. It's practically just connecting the dots in the training set, which isn't helping it fit the test set at all.\n",
    "\n",
    "**Remark:** You actually don't even need a model this big to overfit this dataset. Since there are 24 points in the training set, you only need 23 parameters to fit the training set perfectly with a degree 23 polynomial. Feel free to try it. Just create a linear model with features $x_1=x, x_2=x^2, x_3=x^3, \\cdots, x_{23}=x^{23}$ and fit it to this dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5146cb80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "yhat = model(X)\n",
    "plt.scatter(X_train.cpu().numpy(), y_train.cpu().numpy(), label='train', color='gray', alpha=0.5, s=5)\n",
    "plt.scatter(X_test.cpu().numpy(), y_test.cpu().numpy(), label='test', color='black', alpha=1, s=15)\n",
    "plt.plot(X.cpu().numpy(), yhat.detach().cpu().numpy(), label='$\\hat y$', color='red')\n",
    "plt.xlabel('$x$')\n",
    "plt.ylabel('$y$')\n",
    "plt.legend()\n",
    "plt.title('Overfitted Model')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55b4d680",
   "metadata": {},
   "source": [
    "Why did we overfit this dataset? Well, we specified a huge model to fit only 30 points! Just how big is this model? We can get that with the following function, which uses the pytorch `numel` method to get how many elements are in a tensor, and uses this method on all parameter tensors in the model, and sums them up to get the total number. It looks like this neural network already has over 1.5 million parameters! It's no surprise that a model that big can easily overfit a dataset with just 30 points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "30352030",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1504501"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def num_params(model):\n",
    "    return sum([p.numel() for p in model.parameters()])\n",
    "\n",
    "num_params(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b295f39f",
   "metadata": {},
   "source": [
    "Supposing we were dead set to use this model on this dataset, what could we do to improve results? It turns out there exist a whole set of techniques called **regularization** that can help make it harder for large models to overfit the dataset.\n",
    "\n",
    "Traditionally, the most common thing we might do if our model was overfitting would be to decrease the size of the model. Instead of a complicated model like an 8-layer neural network, maybe use a simpler model like a shallow network or perhaps just linear regression. In the age of deep learning though this approach is less advised. The reason being that you can often *still* get better results with a deeper network than a shallow network, even if you have lots more parameters that can overfit. There are better ways to deal with overfitting. Here are a few.\n",
    "\n",
    "### Weight Decay\n",
    "\n",
    "The simplest such regularization technique is called **weight decay** or **L2 regularization**. The idea here is to add a penalty term to the loss function that discourages it from letting weights grow too large during training. The closer the weights are to zero, the more the model acts like it has fewer parameters, since zeroing weights tends to zero out neurons. Suppose you have a loss function $L(\\hat y, y)$ and your neural network has total weights\n",
    "$$w \\equiv (w_1,w_2,\\cdots,w_m).$$\n",
    "Then we can define an L2-regularized loss function $L_R(\\hat y, y)$ by\n",
    "$$L_R(\\hat y, y) \\equiv L(\\hat y, y) + \\frac{\\lambda}{2N} w\\cdot w = L(\\hat y, y) + \\frac{\\lambda}{2N} \\big(w_1^2 + w_2^2 + \\cdots + w_m^2 \\big).$$\n",
    "That is, it's just the regular loss added to a *penalty term* that's a just a sum of squares of *every single weight* in your neural network. The value $\\lambda$ is the **weight decay rate**. It's another tunable hyperparameter you specify in advance when training a model.\n",
    "\n",
    "To see what weight decay does, remember that the goal of training is to minimize the (regularized) loss $L_R(\\hat y, y)$. With the added penalty term $\\frac{\\lambda}{2N} w\\cdot w$, the model will want to try to keep the weights small during training so that this term doesn't blow up. The weight decay rate $\\lambda$ controls the tradeoff between how badly the model wants to do well on fitting the dataset (the regular loss term), and how badly it wants to keep the weights small (the penalty term). Setting $\\lambda$ appropriately creates a good tradeoff between these two competing objectives.\n",
    "\n",
    "**Note:** The biases aren't generally affected by weight decay. It's only the weights we worry about blowing up. The biases are just additive terms, and there are far fewer of them than weights, so they contribute less to training.\n",
    "\n",
    "In practice, weight decay is usually defined on the gradient descent updates instead of directly on the loss function itself. The mathematically inclined can show that the regularized gradient updates are given by\n",
    "$$\\boldsymbol{W}_{n+1} = \\boldsymbol{W}_n - \\alpha \\frac{dL_R(\\boldsymbol{W}_n,\\boldsymbol{b}_n)}{d\\boldsymbol{W}} = \\bigg(1 - \\frac{\\lambda}{N}\\bigg)\\boldsymbol{W}_n - \\alpha \\frac{dL(\\boldsymbol{W}_n,\\boldsymbol{b}_n)}{d\\boldsymbol{W}},$$\n",
    "$$\\boldsymbol{b}_{n+1} = \\boldsymbol{b}_n - \\alpha \\frac{dL_R(\\boldsymbol{W}_n,\\boldsymbol{b}_n)}{d\\boldsymbol{b}} = \\boldsymbol{b}_n - \\alpha \\frac{dL(\\boldsymbol{W}_n,\\boldsymbol{b}_n)}{d\\boldsymbol{b}}.$$\n",
    "\n",
    "Notice the terms on the right involve gradients of the original loss $L$, not the regularized loss $L_R$. They look exactly like the usual gradient updates, except the weights get decayed by a factor of $\\big(1 - \\frac{\\lambda}{N}\\big)$ on each update, hence the name \"weight decay\". It's in this form that weight decay is typically implemented in practice.\n",
    "\n",
    "In pytorch, we can use weight decay by just passing in the value $\\lambda$ that we want directly into the optimizer with the keyword `weight_decay`. Let's see if we can train a better model to fit the above dataset using weight decay.\n",
    "\n",
    "### Dropout\n",
    "\n",
    "Another way to regularize a model that's neural network specific is to use a special \"layer\" called **dropout**. The idea is this: A model is more likely to overfit when any one neuron is allowed to dominate a prediction too much. We can thus regularize by preventing any one neuron from becoming too influential during training.\n",
    "\n",
    "During **training** we can do the following:\n",
    "- For a given hidden layer $\\ell$ with $n_h$ hidden units, take its post activation outputs $a$, which will have $n_h$ different values (the neurons of that layer).\n",
    "- Instead of feeding all $n_h$ hidden units of $a$ to the next linear layer, randomly sample a certain fraction $p$ of them to mask (i.e. zero out temporarily so they won't affect the output).\n",
    "- The other fraction $1-p$ we'll allow to pass into the activation function and affect the output.\n",
    "- Each time we pass through the layer, we sample a different set from $a$ than we did last time, but still only a $p$ fraction of them\n",
    "- Do this each iteration, for each layer, until training is complete. Note each layer can have different fractions $p$ to mask.\n",
    "\n",
    "Here's a figure showing what applying dropout during training looks like. For each iteration, i.e. each forward pass through the network, the ones that are X'd out will change, but the *number* that are X'd out will always be the same, depending on $p$.\n",
    "\n",
    "<img src=\"https://miro.medium.com/max/1044/1*iWQzxhVlvadk6VAJjsgXgg.png\" alt=\"dropout\" width=\"500\">\n",
    "\n",
    "When doing **inference** on the model, i.e. when making predictions after training, we don't want to keep dropout on. We want to use all the neurons we've got to ensure that our predictions aren't random, but completely stable and deterministic.\n",
    "\n",
    "In pytorch, we can create a dropout layer using `nn.Dropout(p)`, where `p` is the fraction of neurons to mask as described above. During training we'll want dropout to be on. To make sure that's true we set `model = model.train()` before starting training. Once we're *done* training, we want to make sure dropout is turned off. We can do that by setting `model = model.eval()` before making predictions.\n",
    "\n",
    "### Regularization Example\n",
    "\n",
    "Let's use weight decay and dropout for the above example and see if we can reign in the overfitting. We'll use the same model as above, just with dropout added after each linear layer (except the output layer, you don't usually want one there). We'll take $p=0.2$ and $\\lambda=0.001$. How did I arrive at this choice of hyperparameters, you might ask? Lots of times running this thing to see what would give the best result, with all the other hyperparameters from above fixed. Don't think I'm a magician and pulled them out of a hat or anything. Tuning neural nets is a whole lot of trial and error.\n",
    "\n",
    "We can see that we've managed to *halve* our testerror here, but at the cost of the training error being higher. That's what regularization will often do. Notice also that the fitted curve looks a lot nicer than the other one. It's trying to smoothly fit the points better. It's not a line, but it's doing a good job."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dede8803",
   "metadata": {},
   "outputs": [],
   "source": [
    "p = 0.2\n",
    "\n",
    "model = nn.Sequential(\n",
    "    nn.Linear(num_features, num_hidden),\n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(p=p),\n",
    "    nn.Linear(num_hidden, num_hidden),\n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(p=p),\n",
    "    nn.Linear(num_hidden, num_hidden),\n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(p=p),\n",
    "    nn.Linear(num_hidden, num_hidden),\n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(p=p),\n",
    "    nn.Linear(num_hidden, num_hidden),\n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(p=p),\n",
    "    nn.Linear(num_hidden, num_hidden),\n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(p=p),\n",
    "    nn.Linear(num_hidden, num_hidden),\n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(p=p),\n",
    "    nn.Linear(num_hidden, num_targets)\n",
    ")\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "42c4545d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6bab6628a57e4dd9a9a424290ba5378f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter = 0 \t\t train loss = 0.3189311921596527 \t\t test loss = 1.067847490310669\n",
      "iter = 1000 \t\t train loss = 0.03205722197890282 \t\t test loss = 0.0249770674854517\n",
      "iter = 2000 \t\t train loss = 0.028152383863925934 \t\t test loss = 0.021457595750689507\n",
      "iter = 3000 \t\t train loss = 0.03488529846072197 \t\t test loss = 0.023753678426146507\n",
      "iter = 4000 \t\t train loss = 0.03236726298928261 \t\t test loss = 0.039700400084257126\n",
      "iter = 5000 \t\t train loss = 0.03180822357535362 \t\t test loss = 0.03295603394508362\n",
      "iter = 6000 \t\t train loss = 0.031245656311511993 \t\t test loss = 0.04395035281777382\n",
      "iter = 7000 \t\t train loss = 0.03394685313105583 \t\t test loss = 0.03648354485630989\n",
      "iter = 8000 \t\t train loss = 0.028842834755778313 \t\t test loss = 0.03609803318977356\n",
      "iter = 9000 \t\t train loss = 0.02666834555566311 \t\t test loss = 0.03168197348713875\n",
      "iter = 9999 \t\t train loss = 0.028076164424419403 \t\t test loss = 0.03922378271818161\n"
     ]
    }
   ],
   "source": [
    "num_iters = 10_000\n",
    "loss_fn = nn.MSELoss()\n",
    "opt = torch.optim.SGD(model.parameters(), lr=0.01, weight_decay=0.001)\n",
    "for i in tqdm(range(num_iters)):\n",
    "    # training\n",
    "    model = model.train()\n",
    "    opt.zero_grad()\n",
    "    yhat = model(X_train)\n",
    "    loss = loss_fn(yhat, y_train)\n",
    "    loss.backward()\n",
    "    opt.step()\n",
    "    # inference\n",
    "    model = model.eval()\n",
    "    yhat = model(X_test)\n",
    "    test_loss = loss_fn(yhat, y_test)\n",
    "    if i % (num_iters // 10) == 0:\n",
    "        print(f'iter = {i} \\t\\t train loss = {loss / len(X_train)} \\t\\t test loss = {test_loss / len(X_test)}')\n",
    "print(f'iter = {i} \\t\\t train loss = {loss / len(X_train)} \\t\\t test loss = {test_loss / len(X_test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e59913dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "yhat = model(X)\n",
    "plt.scatter(X_train.cpu().numpy(), y_train.cpu().numpy(), label='train', color='gray', alpha=0.5, s=5)\n",
    "plt.scatter(X_test.cpu().numpy(), y_test.cpu().numpy(), label='test', color='black', alpha=1, s=15)\n",
    "plt.plot(X.cpu().numpy(), yhat.detach().cpu().numpy(), label='$\\hat y$', color='red')\n",
    "plt.xlabel('$x$')\n",
    "plt.ylabel('$y$')\n",
    "plt.legend()\n",
    "plt.title('Regularized Model')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "958591aa",
   "metadata": {},
   "source": [
    "## Normalization\n",
    "\n",
    "It turns out that, like all parametric models, neural networks are strongly affected by the scale of the data. If features are way out of scale with each other the model will typically train poorly. For gradient descent to work, you'll either need to use a really small learning rate, or rescale your data prior to training. Since we want to use large learning rates and train our models quickly, rescaling the data seems like the smarter move. This is called **normalization**. In fact, with neural nets, we don't just want to normalize the data (i.e. the input layer), we want to normalize *all layers*. This will lead to layer normalization concepts like batch normalization and layer normalization.\n",
    "\n",
    "Too see what normalization does, let's start with input layer normalization, i.e. normalizing the input features. Consider the following input data `X` with 100 examples of 3 features. We can see how skewed the features are by looking at a histogram of each feature and overlaying them on top of each other. In this case, it looks like the feature $x_0$ has a mean around 0 with a pretty large spread. Feature $x_1$ has a somewhat higher mean, but a smaller spread with a sharper peak. And feature $x_2$ has a much higher mean around 1000 and a still smaller spread and higher peak. It's not at all the case that these features are on the same scale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dcc4b83f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([100, 3])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def gen_data(n_samples, means, stds):\n",
    "    x0 = stds[0] * torch.randn(n_samples).reshape(-1, 1) + means[0]\n",
    "    x1 = stds[1] * torch.randn(n_samples).reshape(-1, 1) + means[1]\n",
    "    x2 = stds[2] * torch.randn(n_samples).reshape(-1, 1) + means[2]\n",
    "    return torch.cat([x0, x1, x2], dim=1)\n",
    "    \n",
    "x = gen_data(100, [1, 100, 1000], [100, 10, 1])\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1d886a9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(x[:, 0].numpy(), label='$x_0$')\n",
    "plt.hist(x[:, 1].numpy(), label='$x_1$')\n",
    "plt.hist(x[:, 2].numpy(), label='$x_2$')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55263415",
   "metadata": {},
   "source": [
    "There are several ways to normalize data, with different domains often preferring different normalization methods. Probably the most common is **standardization**, a method from statistics where one normalizes each feature to have a mean 0 and standard deviation 1, called centering and scaling. If $x_j$ is a feature with mean $\\mu_j$ and standard deviation $\\sigma_j$, we can normalize it to a new feature standardized feature $\\bar x_j$ via\n",
    "$$\\bar x_j \\equiv \\frac{x_j - \\mu_j}{\\sigma_j}.$$\n",
    "By design, all $\\bar x_j$ will have mean 0 and standard deviation 1. Note each feature will have its own $\\mu_j$ and $\\sigma_j$ to normalize by. You don't want to use the same $\\mu$ and $\\sigma$ for every feature or you haven't really normalized your data all.\n",
    "\n",
    "Using broadcasting rules we can normalize a dataset `x` by subtracting a *row vector* of column means and dividing by a *row vector* of column standard deviations. It's a simple one-liner. Once we've done this, the histogram shows each feature to be a lot better scaled."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "02c7356d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([100, 3])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_normed = (x - torch.mean(x, dim=0)) / torch.std(x, dim=0)\n",
    "x_normed.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "100feb97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(x_normed[:, 0].numpy(), label=r'$\\bar x_0$', alpha=0.5)\n",
    "plt.hist(x_normed[:, 1].numpy(), label=r'$\\bar x_1$', alpha=0.5)\n",
    "plt.hist(x_normed[:, 2].numpy(), label=r'$\\bar x_2$', alpha=0.5)\n",
    "plt.legend(fontsize=12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30215a4b",
   "metadata": {},
   "source": [
    "### Batch Normalization\n",
    "\n",
    "The real kick here is that with neural networks we want to do this for *each layer*, not just the inputs, as it will make training deeper networks much easier when neurons in a layer are on similar scales to each other. Generally we'll want to do this after each linear layer before applying the activation function. So if a linear layer has\n",
    "$$\\boldsymbol{z}_{\\ell} = \\boldsymbol{W}_{\\ell} \\boldsymbol{a}_{\\ell-1} + \\boldsymbol{b}_{\\ell},$$\n",
    "we'll want to normalize it to be\n",
    "$$\\boldsymbol{\\hat z}_{\\ell} \\equiv \\frac{\\boldsymbol{z}_{\\ell} - \\boldsymbol{\\mu}_{\\ell}}{\\boldsymbol{\\sigma}_{\\ell}},$$\n",
    "where $\\boldsymbol{\\mu}_{\\ell}$ is the mean of the inputs in layer $\\ell$, and $\\boldsymbol{\\sigma}_{\\ell}$ the standard deviation of those inputs.\n",
    "\n",
    "Excuse the slight abuse of notation here. This formula is already assumed to be vectorized, hence the change to bolded notation. So $\\boldsymbol{z}_{\\ell}$ is a vector with $n_h$ features. And *each of those features* will be normalized by *its own mean and std*.\n",
    "\n",
    "Now, it seems like the thing to do would be to pass $\\boldsymbol{\\hat z}_{\\ell}$ into the activation function like we would usually do $\\boldsymbol{z}_{\\ell}$, but that's not quite what we want to do. The issue is that we have normalized our layer to have the same distribution, a Gaussian. But there's no a priori reason that those features should necessarily be Gaussians with mean 0 and std 1. We want our learned features to be as expressive as possible.\n",
    "\n",
    "The trick for both 1) taking advantage of the benefits of normalized layers in training, while simultaneously 2) having features as expressive as possible can be accomplished as follows: What we'll do is, for each neuron in the layer, introduce two learned parameters, a scale parameter $\\gamma_j$ and a shift parameter $\\beta_j$.\n",
    "\n",
    "For each hidden layer $\\ell$ this will give two parameter vectors: a scale vector $\\boldsymbol{\\gamma}_{\\ell}=(\\gamma_1,\\cdots,\\gamma_{n_h})$, and a shift vector $\\boldsymbol{\\beta}_{\\ell}=(\\beta_1,\\cdots,\\beta_{n_h})$. Using these, we can *elementwise multiply* $\\boldsymbol{\\gamma}_{\\ell}, \\boldsymbol{\\hat z}_{\\ell}$ and add $\\boldsymbol{\\beta}_{\\ell}$ to get the *final* linear layer outputs that'll then be fed into the activation function:\n",
    "$$\\boldsymbol{\\tilde z}_{\\ell} \\equiv \\boldsymbol{\\gamma}_{\\ell} \\boldsymbol{\\hat z}_{\\ell} + \\boldsymbol{\\beta}_{\\ell},$$\n",
    "$$\\boldsymbol{a}_{\\ell} = f_{\\ell}(\\boldsymbol{\\tilde z}_{\\ell}).$$\n",
    "These will allow each neuron to have its own mean and standard deviation, but only after we've normalized the data. The neural network can figure out for itself what the best choices for these parameters are by learning from the data. This technique is called **batch normalization** (batch norm), and has been shown to be very powerful in helping stably train deep neural networks of all kinds.\n",
    "\n",
    "In pytorch, we can create a (1-dim) batch norm layer using `nn.BatchNorm1d`. If that layer has `num_hidden` neurons then batch norm will have `2 * num_hidden` parameters: `num_hidden` scale parameters $\\boldsymbol{\\gamma}$, and `num_hidden` shift parameters $\\boldsymbol{\\beta}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a5ca800d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parameter containing:\n",
       " tensor([1., 1., 1.], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([0., 0., 0.], requires_grad=True)]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_hidden = 3\n",
    "batch_norm = nn.BatchNorm1d(num_hidden)\n",
    "list(batch_norm.parameters()) # these are initialized param values, not yet learned"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d165a2b6",
   "metadata": {},
   "source": [
    "### Layer Normalization\n",
    "\n",
    "For completeness, there's also another normalization technique related to batch norm that's becoming more popular, called **layer normalization** (layer norm). It's almost exactly the same as batch norm, except with one subtle difference: Instead of calculating $\\boldsymbol{\\mu}_{\\ell}$ and $\\boldsymbol{\\sigma}_{\\ell}$ across *all examples* in a batch for *each neuron*, they're calculated for *each example* separately across *all neurons* in the layer.\n",
    "\n",
    "<img src=\"https://i.stack.imgur.com/E3104.png\" alt=\"layer norm\" width=\"500\">\n",
    "\n",
    "This very subtle change has increasingly been shown to work well in many applications, and is widely used in the most modern neural architectures, especially in sequential architectures like transformers and RNNs. Roughly speaking, right now it seems layer norms are more popular with NLP applications, and batch norms with computer vision applications. But this may well change in the next few years.\n",
    "\n",
    "In pytorch, we can create a layer norm layer using `nn.LayerNorm`. It has the same number and type of parameters as batch norm does, they're just calculated slightly differently, as described above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "50a8a21e",
   "metadata": {},
   "outputs": [],
   "source": [
    "nn.LayerNorm?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "61df6f7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parameter containing:\n",
       " tensor([1., 1., 1.], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([0., 0., 0.], requires_grad=True)]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_hidden = 3\n",
    "layer_norm = nn.LayerNorm(num_hidden)\n",
    "list(layer_norm.parameters()) # these are initialized param values, not yet learned"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "997d11ce",
   "metadata": {},
   "source": [
    "## Example: MNIST\n",
    "\n",
    "Let's apply batch norm to the MNIST dataset. Recall that this dataset consists of a few thousand images of 10  handwritten digits 0-9. There are 70,000 images of size 64x64, which when flattened become 768 features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7e303b12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((70000, 784), (70000,))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_mnist_data():\n",
    "    from sklearn.preprocessing import MinMaxScaler\n",
    "    from sklearn.datasets import fetch_openml\n",
    "    data = fetch_openml('mnist_784', version=1, return_X_y=True, as_frame=False)\n",
    "    X = data[0].astype(float)\n",
    "    X = MinMaxScaler(feature_range=(0,1)).fit_transform(X)\n",
    "    y = data[1].astype(int)\n",
    "    return X, y\n",
    "\n",
    "X,y = get_mnist_data()\n",
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4504623e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((60000, 784), (60000,), (10000, 784), (10000,))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=1/7, random_state=seed)\n",
    "X_train.shape, y_train.shape, X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c13a468e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9694"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = RandomForestClassifier(n_estimators=100)\n",
    "model.fit(X_train, y_train)\n",
    "model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "22b89491",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.tensor(X).float().to(device)\n",
    "y = torch.tensor(y).long().to(device)\n",
    "X_train = torch.tensor(X_train).float().to(device)\n",
    "y_train = torch.tensor(y_train).long().to(device)\n",
    "X_test = torch.tensor(X_test).float().to(device)\n",
    "y_test = torch.tensor(y_test).long().to(device)\n",
    "\n",
    "num_features = X_train.shape[1]\n",
    "num_hidden = 500\n",
    "num_targets = len(set(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "352cd76f",
   "metadata": {},
   "outputs": [],
   "source": [
    "p = 0.1\n",
    "model = nn.Sequential(\n",
    "    nn.Linear(num_features, num_hidden),\n",
    "    nn.BatchNorm1d(num_hidden),\n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(p=p),\n",
    "    nn.Linear(num_hidden, num_hidden),\n",
    "    nn.BatchNorm1d(num_hidden),\n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(p=p),\n",
    "    nn.Linear(num_hidden, num_hidden),\n",
    "    nn.BatchNorm1d(num_hidden),\n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(p=p),\n",
    "    nn.Linear(num_hidden, num_hidden),\n",
    "    nn.BatchNorm1d(num_hidden),\n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(p=p),\n",
    "    nn.Linear(num_hidden, num_hidden),\n",
    "    nn.BatchNorm1d(num_hidden),\n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(p=p),\n",
    "    nn.Linear(num_hidden, num_hidden),\n",
    "    nn.BatchNorm1d(num_hidden),\n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(p=p),\n",
    "    nn.Linear(num_hidden, num_hidden),\n",
    "    nn.BatchNorm1d(num_hidden),\n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(p=p),\n",
    "    nn.Linear(num_hidden, num_targets)\n",
    ")\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f230cf70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "73c4017ab84c4159afcd318520d06bf9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "num_iters = 10\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "opt = torch.optim.SGD(model.parameters(), lr=0.001, weight_decay=0.)\n",
    "for i in tqdm(range(num_iters)):\n",
    "    # training\n",
    "    model = model.train()\n",
    "    opt.zero_grad()\n",
    "    yhat = model(X_train)\n",
    "    loss = loss_fn(yhat, y_train)\n",
    "    loss.backward()\n",
    "    opt.step()\n",
    "    # inference\n",
    "    model = model.eval()\n",
    "    yhat = model(X_test)\n",
    "    test_loss = loss_fn(yhat, y_test)\n",
    "    if i % (num_iters // 10) == 0:\n",
    "        print(f'iter = {i} \\t\\t train loss = {loss / len(X_train)} \\t\\t test loss = {test_loss / len(X_test)}')\n",
    "print(f'iter = {i} \\t\\t train loss = {loss / len(X_train)} \\t\\t test loss = {test_loss / len(X_test)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8c9707c",
   "metadata": {},
   "source": [
    "## Optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "599270fe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81dbb738",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scheduler = torch.optim.lr_scheduler.StepLR(opt, num_iters // 3, gamma=0.3)\n",
    "# scheduler.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13c3bef9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dd0c0bd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
